{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU LSTM\n",
    "Attempts to create a GRU LSTM model to use for Yelp Dataset Challenge\n",
    "Based off of TensorFlow Tutorial: https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "import itertools\n",
    "\n",
    "import utils\n",
    "import util\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gru_lstm class\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 300\n",
    "DROPOUT_KEEP_PROB = 0.8\n",
    "HIDDEN_UNITS = 100\n",
    "NUM_LAYERS = 2\n",
    "NUM_EPOCHS = 2\n",
    "NUM_STEPS = 20\n",
    "BATCH_SIZE = 128\n",
    "MAX_EPOCHS = 30\n",
    "EVALUATE_EVERY = 1000\n",
    "CHECKPOINT_EVERY = 1000\n",
    "\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "LEARNING_RATE = 1\n",
    "LEARN_RATE_DECAY = 0.5\n",
    "DECAY_EVERY = 3\n",
    "\n",
    "DATA_PATH = \"./data/\"\n",
    "SAVE_PATH = \"./saves/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses tf.contrib to generate GRU cell\n",
    "# Saves implementing own GRUCell from scratch\n",
    "# Based off of PTB example: # https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py\n",
    "\n",
    "def data_type():\n",
    "    return tf.float32\n",
    "\n",
    "class gru_lstm(object):\n",
    "    def assign_lr(self, session, lr_value):\n",
    "        \"\"\"\n",
    "        :param: lr_value- new learning rate value multiplied by decay rate\n",
    "        \"\"\"\n",
    "        assert isinstance(lr_value, float)\n",
    "        session.run(self._learn_update, feed_dict={self._new_learn_rate: lr_value})\n",
    "        \n",
    "    def gru_cell(self, hidden_state_size, keep_prob, is_training, layer, num_layers):\n",
    "    \n",
    "        assert isinstance(keep_prob, float)\n",
    "        assert isinstance(hidden_state_size, int)\n",
    "        assert isinstance(is_training, bool)\n",
    "        assert isinstance(layer, int)\n",
    "        assert isinstance(num_layers, int)      \n",
    "        if num_layers <= 0:\n",
    "            raise AssertionError(\"Need positive number of layers\")\n",
    "    \n",
    "        cell = tf.contrib.rnn.GRUCell(hidden_state_size)\n",
    "    \n",
    "        if layer == num_layers - 1:\n",
    "            return tf.contrib.rnn.OutputProjectionWrapper(cell,\n",
    "                                                          output_size=6)\n",
    "        elif is_training and keep_prob < 1:\n",
    "            return tf.contrib.rnn.DropoutWrapper(cell,\n",
    "                                                 output_keep_prob=keep_prob)\n",
    "        else:\n",
    "            return cell\n",
    "            \n",
    "    def stacked_gru_graph(self, X_inputs, state_size, keep_prob, num_layers, is_training):\n",
    "        assert isinstance(state_size, int)\n",
    "        assert isinstance(keep_prob, float)\n",
    "        if keep_prob < 0 or keep_prob > 1:\n",
    "            raise AssertionError(\"needs to be a value between 0 and 1\")\n",
    "        assert isinstance(num_layers, int)\n",
    "        assert isinstance(is_training, bool)\n",
    "\n",
    "        stacked_gru = tf.contrib.rnn.MultiRNNCell(\n",
    "            cells=[gru_cell(state_size, keep_prob, _, num_layers, is_training) for _ in range(num_layers)], \n",
    "            state_is_tupl=True)\n",
    "\n",
    "        inputs = tf.unstack(X_inputs, num=num_steps, axis=1)\n",
    "\n",
    "        self._initial_state = cell.zero_state(config.batch_size, data_type())\n",
    "\n",
    "        outputs, state = tf.contrib.rnn.static_rnn(cell, inputs,\n",
    "                                                   initial_state=self._initial_state)\n",
    "\n",
    "        return output, state\n",
    "    \n",
    "    def __init__(self, X_inputs, y_labels, num_steps, batch_size, is_training, \n",
    "                 vocab_size, embedding_size, state_size, num_layers, dropout_keep_prob):\n",
    "        \n",
    "        self.epoch_size = ((len(X_inputs) // batch_size) - 1) // num_steps\n",
    "        self.vocab_size = vocab_size # Dont know if need\n",
    "        self.embedding_size = embedding_size\n",
    "        self.state_size = state_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self._is_training = is_training\n",
    "        \n",
    "        self._cell = None        \n",
    "        embedding = tf.get_variable(\"embedding\", [vocab_size, self.state_size], dtype=data_type())\n",
    "        \n",
    "        inputs = tf.nn.embedding_lookup(embedding, X_inputs)\n",
    "        if is_training and dropout_keep_prob < 1:\n",
    "            inputs = tf.nn.dropout(inputs, dropout_keep_prob)\n",
    "        \n",
    "        # Output is Neural Network\n",
    "        output, state = stacked_gru_graph(X_inputs,\n",
    "                                          state_size,\n",
    "                                          dropout_keep_prob,\n",
    "                                          num_layers,\n",
    "                                          is_training)\n",
    "        \n",
    "        W = tf.get_variable(\"W\", [size, vocab_size], dtype=data_type())\n",
    "        b = tf.get_variable(\"b\", [vocab_size], dtype=data_type())\n",
    "        \n",
    "        \n",
    "        logits = tf.nn.xw_plus_b(output, W, b)\n",
    "        logits = tf.reshape(logits, [self.batch_size, self.num_steps, vocab_size])\n",
    "        \n",
    "        loss = tf.contrib.seq2seq.sequence_loss(logits,\n",
    "                                                y_labels,\n",
    "                                                tf.ones([self.batch_size, self.num_steps], dtype=data_type()),\n",
    "                                                average_across_timesteps=False,\n",
    "                                                average_across_batch=True)\n",
    "                                               \n",
    "        \n",
    "        self._cost = tf.reduce_sum(loss)\n",
    "        self._final_state = state\n",
    "        \n",
    "        self._learn_rate = tf.Variable(0.0, trainable=False) # Learning Rate\n",
    "        gradients, _ = tf.clip_by_global_norm(tf.gradients(self._cost, tvars),\n",
    "                                          config.max_grad_norm)\n",
    "        train_vars = tf.trainable_variables() # Returns all variables specified trainable=True\n",
    "        \n",
    "        optimizer = tf.train.RMSPropOptimizer(self._learn_rate) # Using RMSProp for RNN's rather than SGD as usual\n",
    "        self._train_op = optimizer.apply_gradients(zip(gradients, train_vars),\n",
    "                                                   global_step=tf.train.get_or_create_global_step())\n",
    "        \n",
    "        self._new_learn_rate = tf.placeholder(tf.float32, shape=[], name=\"new_learning_rate\")\n",
    "        self._learn_update = tf.assign(self._learn_rate, self._new_learn_rate)\n",
    "    \n",
    "   \n",
    "        \n",
    "    def export_ops(self, name):\n",
    "        \"\"\"Exports ops to collections.\"\"\"\n",
    "        self._name = name\n",
    "        ops = {util.with_prefix(self._name, \"cost\"): self._cost}\n",
    "        if self._is_training:\n",
    "            ops.update(lr=self._learn_rate, new_learn_rate=self._new_learn_rate, lr_update=self._learn_update)\n",
    "        for name, op in ops.items():\n",
    "            tf.add_to_collection(name, op)\n",
    "        self._initial_state_name = util.with_prefix(self._name, \"initial\")\n",
    "        self._final_state_name = util.with_prefix(self._name, \"final\")\n",
    "        util.export_state_tuples(self._initial_state, self._initial_state_name)\n",
    "        util.export_state_tuples(self._final_state, self._final_state_name)\n",
    "        \n",
    "    def import_ops(self):\n",
    "        if self._is_training:\n",
    "            self._train_op = tf.get_collection_ref(\"train_op\")[0]\n",
    "            self._learn_rate = tf.get_collection_ref(\"lr\")[0]\n",
    "            self._new_learn_rate = tf.get_collection_ref(\"new_lr\")[0]\n",
    "            self._learn_update = tf.get_collection_ref(\"lr_update\")[0]\n",
    "            \n",
    "        self._cost = tf.get_collection_ref(util.with_prefix(self._name, \"cost\"))[0]\n",
    "        num_replicas = 0\n",
    "        self._initial_state = util.import_state_tuples(self._initial_state,\n",
    "                                                       self._initial_state_name,\n",
    "                                                       num_replicas)\n",
    "        self._final_state = util.import_state_tuples(self._final_state,\n",
    "                                                     self._final_state_name,\n",
    "                                                     num_replicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(session, model, eval_op=None, verbose=False):\n",
    "    \"\"\"Runs the model on the given data.\"\"\"\n",
    "    start_time = time.time()\n",
    "    costs = 0.0\n",
    "    iters = 0\n",
    "    state = session.run(model.initial_state)\n",
    "\n",
    "    fetches = {\n",
    "        \"cost\": model.cost,\n",
    "        \"final_state\": model.final_state,\n",
    "    }\n",
    "    if eval_op is not None:\n",
    "        fetches[\"eval_op\"] = eval_op\n",
    "\n",
    "    for step in range(model.input.epoch_size):\n",
    "        feed_dict = {}\n",
    "        for i, (c, h) in enumerate(model.initial_state):\n",
    "            feed_dict[c] = state[i].c\n",
    "            feed_dict[h] = state[i].h\n",
    "\n",
    "    vals = session.run(fetches, feed_dict)\n",
    "    cost = vals[\"cost\"]\n",
    "    state = vals[\"final_state\"]\n",
    "\n",
    "    costs += cost\n",
    "    iters += model.input.num_steps\n",
    "\n",
    "    if verbose and step % (model.input.epoch_size // 10) == 10:\n",
    "        print(\"%.3f perplexity: %.3f speed: %.0f wps\" %\n",
    "            (step * 1.0 / model.input.epoch_size, np.exp(costs / iters), \n",
    "             iters * model.input.batch_size * max(1, FLAGS.num_gpus) /\n",
    "             (time.time() - start_time)))\n",
    "\n",
    "    return np.exp(costs / iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'stacked_gru_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b8f07054e661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomasan/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-b8f07054e661>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 model_train = gru_lstm(xTrain, yTrain, NUM_STEPS, BATCH_SIZE, \n\u001b[1;32m     38\u001b[0m                                  \u001b[0mIS_TRAINING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                                  HIDDEN_UNITS, NUM_LAYERS, DROPOUT_KEEP_PROB)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-cc77b20639d6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X_inputs, y_labels, num_steps, batch_size, is_training, vocab_size, embedding_size, state_size, num_layers, dropout_keep_prob)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# Output is Neural Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         output, state = stacked_gru_graph(X_inputs,\n\u001b[0m\u001b[1;32m     78\u001b[0m                                           \u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                                           \u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'stacked_gru_graph' is not defined"
     ]
    }
   ],
   "source": [
    "def main(_):\n",
    "    \n",
    "    global EMBEDDING_SIZE\n",
    "    global DROPOUT_KEEP_PROB\n",
    "    global HIDDEN_UNITS\n",
    "    global NUM_LAYERS\n",
    "    global NUM_EPOCHS\n",
    "    global BATCH_SIZE\n",
    "    global MAX_EPOCHS\n",
    "    global EVALUATE_EVERY\n",
    "    global CHECKPOINT_EVERY\n",
    "    global NUM_STEPS\n",
    "    \n",
    "    global VOCAB_SIZE\n",
    "    \n",
    "    global LEARN_RATE_DECAY\n",
    "    global DECAY_EVERY\n",
    "    global LEARNING_RATE\n",
    "    \n",
    "    global DATA_PATH\n",
    "    global SAVE_PATH\n",
    "        \n",
    "    DF_reviews = pd.read_csv(DATA_PATH + \"features.csv\")\n",
    "    DF_ratings = pd.read_csv(DATA_PATH + \"stars.csv\")\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        initializer = tf.random_uniform_initializer(-0.1,0.1)\n",
    "        \n",
    "        xTrain, xTest, yTrain, yTest = train_test_split(DF_reviews,\n",
    "                                                        DF_ratings,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=9)\n",
    "        # Defining Training model\n",
    "        with tf.name_scope(\"Train\"):\n",
    "            IS_TRAINING = True\n",
    "            with tf.variable_scope(\"Model\", reuse=None, initializer=initializer):\n",
    "                model_train = gru_lstm(xTrain, yTrain, NUM_STEPS, BATCH_SIZE, \n",
    "                                 IS_TRAINING, VOCAB_SIZE, EMBEDDING_SIZE, \n",
    "                                 HIDDEN_UNITS, NUM_LAYERS, DROPOUT_KEEP_PROB)\n",
    "                \n",
    "            tf.summary.scalar(\"Training Loss\", model_train.cost)\n",
    "            tf.summary.scalar(\"Learning Rate\", model_train.learn_rate)\n",
    "            \n",
    "        with tf.name_scope(\"Test\"):            \n",
    "            with tf.variable_scope(\"Model\", reuse=True, initializer=initializer):\n",
    "                \n",
    "                IS_TRAINING = False\n",
    "                BATCH_SIZE = 1\n",
    "                NUM_STEPS = 1\n",
    "                \n",
    "                model_test = gru_lstm(xTest, yTest, NUM_STEPS, BATCH_SIZE, \n",
    "                                 IS_TRAINING, VOCAB_SIZE, EMBEDDING_SIZE, \n",
    "                                 HIDDEN_UNITS, NUM_LAYERS, DROPOUT_KEEP_PROB)\n",
    "        \n",
    "        \n",
    "        models = {\"Train\": model_train, \"Test\": model_test}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            model.export_ops(name)\n",
    "        \n",
    "        metagraph = tf.train.export_meta_graph()\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        tf.train.import_meta_graph(metagraph)\n",
    "        for model in models.values():\n",
    "            model.import_ops()\n",
    "        sv = tf.train.Supervisor(logdir=FLAGS.save_path)\n",
    "        config_proto = tf.ConfigProto(allow_soft_placement=False)\n",
    "        \n",
    "        with sv.managed_session(config=config_proto) as session:\n",
    "            for i in range(NUM_EPOCHS):\n",
    "                lr_decay = LEARN_RATE_DECAY ** max(i + 1 - DECAY_EVERY, 0.0)\n",
    "                model_train.assign_lr(session, LEARNING_RATE * lr_decay)\n",
    "                \n",
    "                print(\"Epoch: %d Learning rate: %.3f\" % (i + 1, session.run(m.lr)))\n",
    "                train_perplexity = run_epoch(session, m, eval_op=m.train_op, verbose=True)\n",
    "                print(\"Epoch: %d Train Perplexity: %.3f\" % (i + 1, train_perplexity))\n",
    "                valid_perplexity = run_epoch(session, mvalid)\n",
    "                print(\"Epoch: %d Valid Perplexity: %.3f\" % (i + 1, valid_perplexity))\n",
    "                \n",
    "            test_perplexity = run_epoch(session, mtest)\n",
    "            print(\"Test Perplexity: %.3f\" % test_perplexity)\n",
    "            \n",
    "            if SAVE_PATH:\n",
    "                print(\"Saving model to %s.\" % SAVE_PATH)\n",
    "                sv.saver.save(session, SAVE_PATH, global_step=sv.global_step)\n",
    "                \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "Using tf.contrib.keras to preprocess the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
